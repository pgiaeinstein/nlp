{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 1\n",
    "\n",
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = [\n",
    "    'o rei e um homem de bravura',\n",
    "    'a rainha e uma mulher de sabedoria',\n",
    "    'o menino e um homem jovem',\n",
    "    'a menina e uma mulher jovem',\n",
    "    'o principe e um jovem rei',\n",
    "    'a princesa e uma jovem rainha',\n",
    "    'principe e um menino que sera rei',\n",
    "    'princesa e uma menina que sera rainha',\n",
    "    'o homem e bruto',\n",
    "    'a mulher e bonita'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "\n",
    "def remove_sw(documentos):\n",
    "    stop_words = ['e', 'o', 'a', 'um', 'uma', 'sera', 'que', 'de']\n",
    "    resultado = []\n",
    "    for doc in documentos:\n",
    "        tmp = doc.split(' ')\n",
    "        for sw in stop_words:\n",
    "            if sw in tmp:\n",
    "                tmp.remove(sw)\n",
    "        resultado.append(\" \".join(tmp))\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra documentos\n",
    "documentos = remove_sw(documentos)\n",
    "documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um conjunto de palavras (vocabulário)\n",
    "vocabulario = []\n",
    "for doc in documentos:\n",
    "    for palavra in doc.split(' '):\n",
    "        vocabulario.append(palavra)\n",
    "\n",
    "vocabulario = set(vocabulario)\n",
    "vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crio um vetor representativo para cada palavra do vocabulário utilizando Skip-gram com 2 n-grams\n",
    "\n",
    "label_palavra = {}\n",
    "N = 2\n",
    "\n",
    "for i, p in enumerate(vocabulario):\n",
    "    label_palavra[p] = i\n",
    "\n",
    "ss = []\n",
    "for s in documentos:\n",
    "    ss.append(s.split())\n",
    "\n",
    "_dt = []\n",
    "for s in ss:\n",
    "    for index, p in enumerate(s):\n",
    "        for vizinho in s[max(index - N, 0) : min(index + N, len(s)) + 1] : \n",
    "            if vizinho != p:\n",
    "                _dt.append([p, vizinho])\n",
    "                \n",
    "_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(_dt, columns = ['input', 'target'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "OHD = len(vocabulario)\n",
    "\n",
    "def one_hot_encoding(dp):\n",
    "    ohe = np.zeros(OHD)\n",
    "    ohe[dp] = 1\n",
    "    return ohe\n",
    "\n",
    "for i, j in zip(df['input'], df['target']):\n",
    "    inputs.append(one_hot_encoding(label_palavra[i]))\n",
    "    targets.append(one_hot_encoding(label_palavra[j]))\n",
    "\n",
    "X_train = np.asarray(inputs)\n",
    "Y_train = np.asarray(targets)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = (None, OHD))\n",
    "y_label = tf.placeholder(tf.float32, shape = (None, OHD))\n",
    "\n",
    "EMBEDDING = 2 \n",
    "\n",
    "W_1 = tf.Variable(tf.random_normal([OHD, EMBEDDING]))\n",
    "b_1 = tf.Variable(tf.random_normal([1]))\n",
    "densa = tf.add(tf.matmul(x, W_1), b_1)\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([EMBEDDING, OHD]))\n",
    "b_2 = tf.Variable(tf.random_normal([1]))\n",
    "pred = tf.nn.softmax(tf.add( tf.matmul(densa, W_2), b_2))\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(pred), axis = [1]))\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteracao = 25000\n",
    "for i in range(iteracao):\n",
    "    sess.run(train_op, feed_dict = {x: X_train, y_label: Y_train})\n",
    "    if i % 5000 == 0:\n",
    "        print('iteração {0} - loss {1}'.format(str(i), sess.run(loss, feed_dict={x: X_train, y_label: Y_train})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetores = sess.run(W_1 + b_1)\n",
    "vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df = pd.DataFrame(vetores, columns = ['x', 'y'])\n",
    "w2v_df['palavra'] = vocabulario\n",
    "w2v_df = w2v_df[['palavra', 'x', 'y']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize = (15, 15))\n",
    "\n",
    "for p, x, y in zip(w2v_df['palavra'], w2v_df['x'], w2v_df['y']):\n",
    "    ax.annotate(p, (x, y))\n",
    "    \n",
    "_P = 1.0\n",
    "ax_min = np.amin(vetores, axis = 0)[0] - _P\n",
    "ax_max = np.amax(vetores, axis = 0)[0] + _P\n",
    "ay_min = np.amin(vetores, axis = 0)[1] - _P\n",
    "ay_max = np.amax(vetores, axis = 0)[1] + _P\n",
    " \n",
    "plt.xlim(ax_min, ax_max)\n",
    "plt.ylim(ay_min, ay_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio\n",
    "\n",
    "Com a base de laudos fornecida, experimente utilizar a mesma lógica proposta acima para gerar uma rede através da biblioteca GenSim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
