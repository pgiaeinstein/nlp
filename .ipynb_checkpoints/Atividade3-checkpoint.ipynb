{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Atividade 3\n",
    "\n",
    "## Redes Neurais Recorrentes\n",
    "\n",
    "Discutimos como uma rede neural recorrente, através de suas células de memória, permitem processamento de dados sequencial. Também falamos sobre embedding e fizemos um exercício para entender o objetivo e função de um Word2Vec.\n",
    "\n",
    "A biblioteca Keras traz acesso alto nível a camadas que permitem a fácil implementação deste tipo de layer.\n",
    "\n",
    "Este tipo de técnica é boa para generalizar informação esparsa condensando em uma camada densa:\n",
    "\n",
    "![word embeddings vs. one hot encoding](https://s3.amazonaws.com/book.keras.io/img/ch6/word_embeddings.png)\n",
    "\n",
    "Vamos ver exemplos de implementação destas camadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM, CuDNNLSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacks de RNNs\n",
    "\n",
    "Em alguns casos, é interessante criar uma sequência de camadas recorrentes para processamento da informação. Nestes casos é necessário retornar as sequências para compartilhar com suas camadas vizinhas, com exceção da camada final. Este processo é feito passando o valor booleano `True` no o parâmetro `return_sequences` destas camadas, veja exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))  # Este layer final apenas retorna os últimos outputs.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise e classificação de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "Nesta atividade utilizaremos um _dataset_ chamado __IMDB__ composto de opiniões sobre filmes em formato textual. O objetivo é classificar estes _inputs_ de forma binária (0 e 1) onde identificaremos se a opinião é _**positiva**_ ou _**negativa**_.\n",
    "\n",
    "__IMDB__ (Internet Movie DataBase) conta com um total de 50.000 opiniões sobre filmes onde separamos 25.000 delas para treino e os 50% restantes para teste. As frações são balanceadas, ou seja, contem um número igual de opiniões positivas e negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000 # Número máximo de palavras consideradas como features\n",
    "max_len      = 500 # Tamanho máximo do texto utilizado como input\n",
    "batch_size   = 32 # Tamanho do batch de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(len(x_train), 'sequências de treino')\n",
    "print(len(x_test), 'sequências de teste')\n",
    "\n",
    "print('PadSequences (amostras x tamanho)')\n",
    "input_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "input_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PadSequence\n",
    "\n",
    "Precisamos formatar um padrão de input para nossa rede. Definimos que nosso input máximo são 500 palavras. O que este processo faz é cortar textos maiores e preencher com 0 o que falta para completar 500 posições em textos menores que 500 palavras em seu conteúdo.\n",
    "\n",
    "Veja exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train[0]))\n",
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ter ideia do conteúdo deste dado, é possível baixar o dicionário representativo da informação. Da mesma maneira que fizemos na aula passada, podemos consultar o valor de cada número neste dicionário.\n",
    "\n",
    "Veja o exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_palavras = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_palavras['woody']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dicionário possui o valor da palavra como chave, podemos inverter seu conteúdo de `palavra : número` para `número : palavra` para facilitar nosso processamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_palavras_formatado = dict([(valor, chave) for (chave, valor) in dic_palavras.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_palavras_formatado[2289]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos iterar sobre o vetor de _input_ traduzindo a informação, vejamos o exemplo na posição `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = []\n",
    "\n",
    "for item in x_train[0]:\n",
    "    texto.append(dic_palavras_formatado.get(item, '?'))\n",
    "    \n",
    "print(texto)\n",
    "print('------------------*------------------')\n",
    "print(' '.join(texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a rede\n",
    "\n",
    "Podemos treinar uma rede de arquitetura simples para resolver o problema acima utilizando as camadas de `Embedding` e `SimpleRNN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, acc] = model.evaluate(input_test, y_test)\n",
    "print(\"Acc: {:.4f}\".format(acc))\n",
    "\n",
    "acc      = history.history['acc']\n",
    "val_acc  = history.history['val_acc']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Acc no treino')\n",
    "plt.plot(epochs, val_acc, label='Acc da validação')\n",
    "plt.title('Acc no treino e validação')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Loss no treino')\n",
    "plt.plot(epochs, val_loss, label='Loss na validação')\n",
    "plt.title('Loss no treino e validação')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(input_test).flatten()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_preds)\n",
    "auc_calc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(fpr, tpr, label='Modelo (area = {:.3f})'.format(auc_calc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='best')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "Vamos para um exemplo mais objetivo, vamos implementar a mesma arquitetura utilizando uma camada de **LSTM**.\n",
    "\n",
    "Keras traz uma implementação para processamento em GPUs com arquitetura CUDA. Se em seu ambiente, você possui uma GPU com este tipo de arquitetura, pode utilizar a classe `CuDNNLSTM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, acc] = model.evaluate(input_test, y_test)\n",
    "print(\"Acc: {:.4f}\".format(acc))\n",
    "\n",
    "acc      = history.history['acc']\n",
    "val_acc  = history.history['val_acc']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Acc no treino')\n",
    "plt.plot(epochs, val_acc, label='Acc da validação')\n",
    "plt.title('Acc no treino e validação')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Loss no treino')\n",
    "plt.plot(epochs, val_loss, label='Loss na validação')\n",
    "plt.title('Loss no treino e validação')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(input_test).flatten()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_preds)\n",
    "auc_calc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(fpr, tpr, label='Modelo (area = {:.3f})'.format(auc_calc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='best')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "\n",
    "Neste próximo exemplo, vamos estudar uma forma de implementar um chatbot simples. Seu nome é Rose em homenagem ao desenho Os Jetsons de Hanna-Barbera.\n",
    "\n",
    "![Rose](https://i.ytimg.com/vi/xCiQIKtuB6A/maxresdefault.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from unidecode import unidecode \n",
    "\n",
    "import colorama\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_conhecimento = {\n",
    "    'base' : [\n",
    "        {\n",
    "            'label' : 'INIT',\n",
    "            'X'     : ['Olá', 'Oi', 'bom dia', 'boa tarde', 'boa noite', 'como vai?', 'tem alguem ai?'],\n",
    "            'Y'     : ['olá', 'como vai?', 'como posso ajudar?']\n",
    "        },\n",
    "        {\n",
    "            'label' : 'END',\n",
    "            'X'     : ['tchau', 'até logo', 'obrigado pela ajuda'],\n",
    "            'Y'     : ['Sem problemas!', 'Meu prazer!']\n",
    "        },\n",
    "        {\n",
    "            'label' : 'BOT_INFO',\n",
    "            'X'     : ['qual e o seu nome?', 'como posso te chamar?', 'com quem falo?'],\n",
    "            'Y'     : ['Você pode me chamar de rose!', 'Meu nome e rose!', 'Me chamo rose!']\n",
    "        },\n",
    "        {\n",
    "            'label' : 'BOT_SOBRE',\n",
    "            'X'     : ['quem e voce?', 'fale sobre você', 'pode se apresentar?'],\n",
    "            'Y'     : ['Siri é passado! sou a Rose, seu robo assistente!', 'Meu nome é Rose, sou um chatbot!']\n",
    "        },\n",
    "        {\n",
    "            'label' : 'BOT_AGRADECIMENTO',\n",
    "            'X'     : ['obrigado', 'muito obrigado'],\n",
    "            'Y'     : ['Foi um prazer ajudar!', 'Obrigado!']\n",
    "        },\n",
    "        {\n",
    "            'label' : 'BOT_AGENDAMENTO',\n",
    "            'X'     : ['quero agendar um exame', 'gostaria de saber sobre a disponibilidade de agenda para um exame', 'posso agendar um exame?', 'preciso realizar um agendamento de exame'],\n",
    "            'Y'     : ['Ok, qual exame precisa agendar?', 'Certo! Preciso de mais informações. Qual exame gostaria de agendar?']\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando o dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list()\n",
    "y_train = list()\n",
    "labels = list()\n",
    "target = dict()\n",
    "\n",
    "for item in base_conhecimento['base']:\n",
    "    for x in item['X']:\n",
    "        x_train.append(unidecode(x.lower()))\n",
    "        y_train.append(item[ 'label'])\n",
    "    \n",
    "    if item['label'] not in labels:\n",
    "        labels.append(item['label'])\n",
    "        \n",
    "    target[item['label']] = item['Y']\n",
    "    \n",
    "n_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando rótulos para cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma estrutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 25\n",
    "embedding_dim = 32\n",
    "max_len = 50\n",
    "unk_token = '<UNK>'\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=unk_token)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "pad_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, truncating='post', maxlen=max_len)\n",
    "\n",
    "words_idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(pad_sequences, np.array(y_train), epochs=250, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando a Rose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    max_len = 50\n",
    "    \n",
    "    print(f'{Fore.RED}Chatbot ativo, envie \"sair\" para finalizar...{Style.RESET_ALL}')\n",
    "    \n",
    "    while True:\n",
    "        print(f'{Fore.GREEN}Usuário: {Style.RESET_ALL}', end=' ')\n",
    "        texto = unidecode(input().lower())\n",
    "        \n",
    "        if texto == 'sair':\n",
    "            break\n",
    "            \n",
    "        result = model.predict(tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([texto]), truncating='post', maxlen=max_len))\n",
    "        label = encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        responses = target.get(label[0], None)\n",
    "        \n",
    "        if responses == None:\n",
    "            print(f'{Fore.RED}Oooops...{Style.RESET_ALL}')\n",
    "            continue\n",
    "        \n",
    "        response = np.random.choice(responses)\n",
    "        \n",
    "        print(f'{Fore.RED}Rose: {Style.RESET_ALL}{response}')\n",
    "        \n",
    "    print(f'{Fore.RED}Chatbot offline...{Style.RESET_ALL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício Proposto\n",
    "\n",
    "Explore outras arquiteturas de rede e veja se você consegue obter melhores resultados com o exemplo visto acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura\n",
    "\n",
    "### Um problema de previsão\n",
    "\n",
    "Problemas envolvendo sequências podem ser encontrados em outros formatos. No meio médico; Sequências de imagens em um exame de tomografia ou valores de oxigenação de um paciente monitorado, são exemplos.\n",
    "\n",
    "Pensando em negócio, um modelo capaz de prever temperatura em um certo período pode ser utilizado como feature em um motor de tomada de decisão. Dentro do meio hospitalar, pode ser utilizado como feature para prever a demanda diária de uma unidade de pronto atendimento.\n",
    "\n",
    "O artigo em anexo abaixo faz parte do livro [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff) e traz um exemplo de previsão utilizando um conjunto de informações coletadas na estação meteorológica do [Instituto Max-Plank para biogeoquímica em Jena na Alemanha](http://www.bgc-jena.mpg.de/wetter/).\n",
    "\n",
    "Além de trazer o uso de LSTMs bidirecionais, o que veremos na próxima aula deste curso, mostra um exemplo de consumo sequencial de informação pela rede.\n",
    "\n",
    "[Link para download da base](https://www.kaggle.com/stytch16/jena-climate-2009-2016)\n",
    "\n",
    "[Link para o artigo](https://colab.research.google.com/github/pgiaeinstein/nlp/blob/master/fcholletRNNS.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Atividade_1.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_text_classification.ipynb",
     "timestamp": 1541690672629
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
