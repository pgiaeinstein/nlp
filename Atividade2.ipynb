{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTFQV-ZjefPQ"
   },
   "source": [
    "# Atividade 2\n",
    "\n",
    "## Regex\n",
    "\n",
    "Python possui uma biblioteca própria para operações envolvendo expressões regulares. Você pode consultar a [documentação da biblioteca neste link](https://docs.python.org/3/library/re.html) e [alguns exemplos de uso aqui](https://docs.python.org/3/howto/regex.html).\n",
    "\n",
    "Um ótimo local para validar o funcionamento das regras online é através da plataforma [regex101.com](https://regex101.com/). Está plataforma permite compilação de regras e inclusive testando seu funcionamento em python.\n",
    "\n",
    "Vamos utilizar o texto abaixo como exemplo para as operações futuras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "texto = 'abacaxi, abacate, abajur, abacaxi, ameixa, banana, abobrinha, 10/04/2019 10/04/19 10/4/19 3-4-2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplos\n",
    "\n",
    "Dado o texto acima, vamos pensar numa regra para identificar todas as palavras iniciadas em \"aba\".\n",
    "\n",
    "O método `compile` permite compilar regras visando performance na busca por padrões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'aba[\\w]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 7), match='abacaxi'>\n",
      "<re.Match object; span=(0, 7), match='abacaxi'>\n",
      "['abacaxi', 'abacate', 'abajur', 'abacaxi']\n",
      "<callable_iterator object at 0x7f94e116a8d0>\n"
     ]
    }
   ],
   "source": [
    "print(regex.match(texto)) # Determine if the RE matches at the beginning of the string.\n",
    "print(regex.search(texto)) # Scan through a string, looking for any location where this RE matches.\n",
    "print(regex.findall(texto)) # Find all substrings where the RE matches, and returns them as a list.\n",
    "print(regex.finditer(texto)) # Find all substrings where the RE matches, and returns them as an iterator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que nos dois primeiros casos, o resultado que tivemos foi um objeto do tipo `SRE_Match`. Este tipo de objeto nos permite acesso a 4 importantes informações sobre o achado, são elas:\n",
    "\n",
    "1. `group()`: Retorna qual é a string resultante do achado;\n",
    "2. `start()`: Retorna qual é a posição inicial do achado no documento;\n",
    "3. `end()`  : Retorna qual é a posição final do achado no documento;\n",
    "4. `span()` : Retorna uma tupla no formato `(pos_inicial, pos_final)` do achado no documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group(): abacaxi\n",
      "start(): 0\n",
      "end()  : 7\n",
      "span() : (0, 7)\n"
     ]
    }
   ],
   "source": [
    "result = regex.match(texto)\n",
    "print(f'group(): {result.group()}')\n",
    "print(f'start(): {result.start()}')\n",
    "print(f'end()  : {result.end()}')\n",
    "print(f'span() : {result.span()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O terceiro resultado volta uma lista de strings contendo os achados no documento e o quarto nos retornou um objeto do tipo `iterator`. Este objeto é uma lista de achados (objetos do tipo `SRE_Match`), o que nos permite realizar encontrar todos os valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termo encontrado foi \"abacaxi\". Sua posição inicial é 0 e final 7.\n",
      "Termo encontrado foi \"abacate\". Sua posição inicial é 9 e final 16.\n",
      "Termo encontrado foi \"abajur\". Sua posição inicial é 18 e final 24.\n",
      "Termo encontrado foi \"abacaxi\". Sua posição inicial é 26 e final 33.\n"
     ]
    }
   ],
   "source": [
    "for achado in regex.finditer(texto):\n",
    "    print(f'Termo encontrado foi \"{achado.group()}\". Sua posição inicial é {achado.start()} e final {achado.end()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que temos 4 tipos de formatação diferentes para datas em nossa string de exemplo, vamos ver uma forma de identificar todas elas com apenas uma regra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regex = re.compile(r'\\d{1,2}[\\/-]?\\d{1,2}[\\/-]?\\d{2,4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termo encontrado foi \"10/04/2019\". Sua posição inicial é 62 e final 72.\n",
      "Termo encontrado foi \"10/04/19\". Sua posição inicial é 73 e final 81.\n",
      "Termo encontrado foi \"10/4/19\". Sua posição inicial é 82 e final 89.\n",
      "Termo encontrado foi \"3-4-2019\". Sua posição inicial é 90 e final 98.\n"
     ]
    }
   ],
   "source": [
    "for achado in data_regex.finditer(texto):\n",
    "    print(f'Termo encontrado foi \"{achado.group()}\". Sua posição inicial é {achado.start()} e final {achado.end()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das operações permitidas pela biblioteca `re` é a de substituição de achados através do método `sub(string_sub, texto)`, vejamos um exemplo trocando todos os achados de data por \"!!\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regex.sub('!!', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = pd.read_excel('https://raw.githubusercontent.com/pgiaeinstein/nlp/master/exemplo_prox_aula.xlsx')\n",
    "dt_coronaria = pd.read_excel('https://raw.githubusercontent.com/pgiaeinstein/nlp/master/data_coronaria.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio - Extração de Entidades\n",
    "\n",
    "Vamos automatizar a anotação dos laudos através de um processo chamado _weak labeling_, isso é, vamos utilizar de expressões regulares para identificar todos os nomes de vaso encontrados nos documentos. Nosso objetivo final com os laudos de angiotomografia de coronária é conseguir identificar os termos que caracterizam informações importantes dos vasos descritos no documento.\n",
    "\n",
    "O que esperamos de resultado é algo como o demonstrado abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que temos o conteúdo dos laudos relacionando a cada palavra uma classe específica. As palavras sem classe definida recebem o valor `O`.\n",
    "\n",
    "Nosso objetivo inicial é encontrar todas as entidades textuais (palavras) onde consigo identificá-las como vasos.\n",
    "\n",
    "Um amigo radiologista analisou o problema e fez uma relação dos possíveis vasos presentes nos documentos, são eles:\n",
    "\n",
    "* descendente anterior\n",
    "* coronaria direita\n",
    "* coronaria esquerda\n",
    "* circunflexa\n",
    "* primeiro ramo marginal\n",
    "* segundo ramo marginal\n",
    "* terceiro ramo marginal\n",
    "* primeiro ramo diagonal\n",
    "* segundo ramo diagonal\n",
    "* terceiro ramo diagonal\n",
    "* ventricular posterior\n",
    "* arteria diagonalis\n",
    "* descendente posterior\n",
    "\n",
    "Vamos salvar o dado processado em um banco de dados NoSQL orientado a documentos respeitando a seguinte estrutura:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"texto\" : string com o texto do documento,\n",
    "    \"entidades\" : Lista com objetos do tipo entidade\n",
    "}\n",
    "```\n",
    "\n",
    "Veja a estrutura dos objetos do tipo entidade:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"palavra\" : string com o achado textual da regra,\n",
    "    \"classe\" : string com a classe do achado,\n",
    "    \"pos_inicial\" : inteiro com o valor inicial do achado em relação ao documento,\n",
    "    \"pos_final\" : inteiro com o valor inicial do achado em relação ao documento\n",
    "}\n",
    "```\n",
    "\n",
    "Considere que todos os achados pertencem a classe `vaso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = dt_coronaria.loc[:9, ['texto']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"(descendente anterior|descendente posterior|coronaria (esquerda|direita)|circunflexa|ventricular posterior|arteria diagonalis|((primeiro|segundo|terceiro|quarto)(\\se\\s|\\s))+(ramos?)?\\s?(diagon(al|ais)?|margin(al|ais)?)?)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos 10 documentos do nosso corpus, realize o processamento na lista `documentos`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Atividade_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
